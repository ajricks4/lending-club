{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas_profiling as pdp\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['font.size'] = 15.0\n",
    "%matplotlib inline\n",
    "import imp\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBRFClassifier,XGBClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV, train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, accuracy_score\n",
    "from numpy.linalg import svd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA, NMF\n",
    "from os import listdir\n",
    "import warnings\n",
    "from xgboost import XGBRFClassifier\n",
    "import tensorflow as tf\n",
    "warnings.filterwarnings('ignore')\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.LC_Clean_Assist as LCC\n",
    "import src.LC_Plotter as LCP\n",
    "import src.LC_Transformer as LCT\n",
    "import src.LC_Models as LCM\n",
    "imp.reload(LCP)\n",
    "imp.reload(LCC)\n",
    "imp.reload(LCT)\n",
    "imp.reload(LCM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/LC_Compiled.csv',low_memory=False)\n",
    "print('{} Loans and {} Features'.format(df.shape[0],df.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = LCC.clean_lc_for_plotting(df)\n",
    "ls_df = df.groupby('loan_status').sum().reset_index()[['loan_status','loan_amnt']]\n",
    "ls_df['loan_amnt'] = round(ls_df['loan_amnt'] / 1000000,1)\n",
    "ls_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LCP.plot_loan_breakdown_pie(df)\n",
    "LCP.plot_grade_breakdown_pie(df)\n",
    "grade_pie = df.groupby('grade').sum()[['loan_amnt','total_rec_prncp','out_prncp','delinq_amnt','charged_off_amnt']]\n",
    "grade_pie.reset_index(inplace=True)\n",
    "grade_pie['bad_debt'] = grade_pie['delinq_amnt'] + grade_pie['charged_off_amnt']\n",
    "grade_pie[['total_rec_prncp','out_prncp','bad_debt']] = grade_pie[['total_rec_prncp','out_prncp','bad_debt']] /1000000\n",
    "grade_pie[['grade','total_rec_prncp','out_prncp','bad_debt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LCP.choro_debt_state(df)\n",
    "LCP.choro_debt_state_count(df)\n",
    "df.groupby('addr_state').mean().reset_index()[['addr_state','loan_amnt']].sort_values(by='loan_amnt',ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LCP.lc_time_series(df)\n",
    "ts_group = df.groupby('issue_d').sum()\n",
    "ts_group.reset_index(inplace=True)\n",
    "max_idx = np.argmax(ts_group['loan_amnt'])\n",
    "ts_group[ts_group.index == max_idx][['issue_d','loan_amnt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_group['year'] = ts_group['issue_d'].apply(lambda x: str(x).split('-')[0])\n",
    "ts_group.groupby('year').sum()['loan_amnt'] / 1000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LCP.lc_individual_profile(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = LCC.clean_lc_for_models(df)\n",
    "returns = LCP.lc_returns(df)\n",
    "returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_36 = returns[returns['term'] == 36]\n",
    "LCP.lc_plot_returns(returns_36,'Returns by Grade (36 Month Term)','images/36_month_returns.png')\n",
    "returns_60 = returns[returns['term'] == 60]\n",
    "LCP.lc_plot_returns(returns_60,'Returns by Grade (60 Month Term)','images/60_month_returns.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LCP.lc_plot_annualized_returns(returns_36,'Annualized Returns by Grade (36 Month Term)','images/36_month_annualized.png')\n",
    "LCP.lc_plot_annualized_returns(returns_60,'Annualized Returns by Grade (60 Month Term)','images/60_month_annualized.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['purpose'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['total_pymnt'] - df['installment']*df['term'] == 0.0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['total_pymnt'] - (df['installment']*df['term'])) <= 100].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['expected'] = df['installment'] * df['term']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LCP.lc_proportions_time(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df = LCT.lc_transform(df)\n",
    "LCP.pca_plotter(scaled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df = LCT.get_pca_df(scaled_df,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "\n",
    "penalty = ['l1']\n",
    "C = np.arange(0.05,0.6,0.05)\n",
    "logm = LogisticRegression(solver = 'liblinear')\n",
    "logm_grid = GridSearchCV(logm,dict(penalty=penalty,C=C),cv=3)\n",
    "logm_output_df = LCM.lc_proportion_grid_search(pca_df,logm_grid,list(np.arange(0.025,1.01,0.005)))\n",
    "\n",
    "params = {'n_estimators':[25,50],\n",
    "          'max_depth':[4,8],\n",
    "          'min_samples_split':[5],\n",
    "          'min_samples_leaf':[2],\n",
    "          'max_features':['auto','sqrt'],\n",
    "         }\n",
    "rfc = RandomForestClassifier()\n",
    "rfc_grid = GridSearchCV(rfc,params,cv=3,n_jobs=-1)\n",
    "rfc_output_df = LCM.lc_proportion_grid_search(pca_df,rfc_grid,list(np.arange(0.025,1.01,0.005)))\n",
    "\n",
    "param_grid = {'learning_rate':[0.1],\n",
    "          'n_estimators':[25,50,75],\n",
    "          'max_features':['auto']\n",
    "}\n",
    "gbc = GradientBoostingClassifier()\n",
    "gbc_grid = GridSearchCV(gbc,param_grid,cv=3,n_jobs=-1)\n",
    "gbc_output_df = LCM.lc_proportion_grid_search(pca_df,gbc_grid,list(np.arange(0.025,1.01,0.005)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "-  The grid search produces the following csv files:\n",
    "    -  'models/logm_optimized.csv'\n",
    "    -  'models/rfc_optimized.csv'\n",
    "    -  'models/gbc_optimized.csv'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logm_optimized = pd.read_csv('models/logm_optimized.csv')\n",
    "rfc_optimized = pd.read_csv('models/rfc_optimized.csv')\n",
    "gbc_df = pd.read_csv('models/gbc_optimized.csv')\n",
    "combined = pd.concat([logm_optimized,rfc_optimized,gbc_df])\n",
    "LCP.plot_36m_returns(combined)\n",
    "LCP.plot_60m_returns(combined)\n",
    "LCP.plot_prec_by_prop(combined)\n",
    "LCP.plot_36m_deployed(combined)\n",
    "LCP.plot_60m_deployed(combined)\n",
    "LCP.plot_rets_v_acc(combined)\n",
    "LCP.plot_rets_v_prec(combined)\n",
    "LCP.profits_v_deployed(combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharpe Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharpe_matrix = LCT.get_compiled_models(combined)\n",
    "df_opt = pd.read_csv('models/sharpe_optimized.csv')\n",
    "df_r = pd.read_csv('models/sharpe_large_deployed.csv')\n",
    "df = pd.concat([df_opt,df_r])\n",
    "df_sharpe = LCM.sharpe_calc_df(df)\n",
    "LCP.plot_sharpe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sharpe[df_sharpe['Sharpe_60'] == df['Sharpe_60'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sharpe[df_sharpe['Sharpe_36'] == df['Sharpe_36'].max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = 0.085\n",
    "p2 = 0.09\n",
    "mod_36m_params = ast.literal_eval(df_sharpe[df_sharpe['Sharpe_36'] == df['Sharpe_36'].max()]['Parameters'].values[0])\n",
    "mod_60m_params = ast.literal_eval(df_sharpe[df_sharpe['Sharpe_60'] == df['Sharpe_60'].max()]['Parameters'].values[0])\n",
    "logr = LogisticRegression(**mod_36m_params)\n",
    "rfc = RandomForestClassifier(**mod_60m_params)\n",
    "rets = []\n",
    "rets_36 = []\n",
    "rets_60 = []\n",
    "deployed = []\n",
    "deployed_36 = []\n",
    "deployed_60 = []\n",
    "for j in range(1000):\n",
    "    print('Running Iteration: {}'.format(j+1))\n",
    "    overall_return, deployed_capital, returned_capital, t_36_rets,t_36_deployed,t_36_pl,t_60_rets,t_60_deployed,t_60_pl = LCM.final_system(pca_df,logr,rfc,p1,p2)\n",
    "    rets.append(overall_return)\n",
    "    rets_36.append(t_36_rets)\n",
    "    rets_60.append(t_60_rets)\n",
    "    deployed.append(deployed_capital)\n",
    "    deployed_36.append(t_36_deployed)\n",
    "    deployed_60.append(t_60_deployed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (40,40))\n",
    "ax1 = fig.add_subplot(3,1,1)\n",
    "ax1.hist(rets,color='darkblue')\n",
    "ax1.tick_params('x',labelsize=40)\n",
    "ax1.set_yticklabels([])\n",
    "plt.title('Distribution of Blended Returns',fontsize=50,fontweight='bold')\n",
    "ax2 = fig.add_subplot(3,1,2)\n",
    "ax2.hist(rets_36,color='darkblue')\n",
    "ax2.tick_params('x',labelsize=40)\n",
    "ax2.set_yticklabels([])\n",
    "plt.title('Distribution of 36 Month Returns',fontsize=50,fontweight='bold')\n",
    "ax3 = fig.add_subplot(3,1,3)\n",
    "ax3.hist(rets_60,color='darkblue')\n",
    "ax3.tick_params('x',labelsize=40)\n",
    "ax3.set_yticklabels([])\n",
    "plt.title('Distribution of 60 Month Returns',fontsize=50,fontweight='bold');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(40,40))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.scatter(np.array(deployed) / 1000000000,rets,c='darkblue',alpha=0.5)\n",
    "plt.title('Returns vs. Deployed Capital',fontsize=40,fontweight='bold')\n",
    "plt.xlabel('Deployed Capital in Millions',fontsize=35)\n",
    "plt.ylabel('Returns',fontsize=35)\n",
    "ax.tick_params('x',labelsize=35)\n",
    "ax.tick_params('y',labelsize=35);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
